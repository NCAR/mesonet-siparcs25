apiVersion: v1
data:
  app.py: "from flask import Flask, render_template, request, jsonify\nfrom flask_socketio import SocketIO\nfrom collections import defaultdict\nfrom threading import Lock\nimport logging\nimport time\nimport os\nimport yaml\nfrom network import DynamicAssignmentNetwork\nfrom mqtt_client import MQTTClient\n\n# Configure logging\nlogging.basicConfig(\n    level=logging.DEBUG,\n    format='%(asctime)s [%(levelname)s] %(message)s',\n    datefmt='%Y-%m-%d %H:%M:%S'\n)\nlogger = logging.getLogger(__name__)\n\n# Load configuration\nwith open('config.yml', 'r') as f:\n    config = yaml.safe_load(f)\n\n# Global variables\nstations = defaultdict(dict)\npis = {}\nstations_lock = Lock()\npending_stations = {}\napp = Flask(__name__, template_folder='templates')\napp.config['SECRET_KEY'] = os.urandom(24)\nallowed_origins = [\n    \"*\",\n    \"http://localhost:5000\",\n    f\"http://{config['web']['host']}:{config['web']['port']}\"\n] + os.getenv(\"ALLOWED_ORIGINS\", \"\").split(\",\")\nallowed_origins = [origin for origin in allowed_origins if origin]\nlogger.info(f\"Allowed CORS origins: {allowed_origins}\")\nsocketio = SocketIO(app, cors_allowed_origins=allowed_origins, async_mode='gevent', logger=True, engineio_logger=True)\n\n# Initialize assignment network\nassignment_network = DynamicAssignmentNetwork(\n    mqtt_client=None,\n    config=config,\n    hysteresis=config.get('assignment', {}).get('hysteresis', 0.1),\n    rssi_min=config.get('assignment', {}).get('rssi_min', -120),\n    rssi_max=config.get('assignment', {}).get('rssi_max', -30)\n)\n\n# Initialize MQTT client\nmqtt_client = MQTTClient(config, stations, pis, stations_lock, pending_stations, assignment_network, socketio)\nassignment_network.mqtt_client = mqtt_client\nlogger.info(\"Starting MQTT client\")\nmqtt_client.connect(config)\n\n\n# Periodic cleanup\nlast_cleanup = time.time()\n\ndef cleanup_stations():\n    global last_cleanup\n    current_time = time.time()\n    if current_time - last_cleanup >= 1:\n        mqtt_client.reconnect()\n        timeout = config['mqtt'].get('assignment_timeout', 60)\n        with stations_lock:\n            stations_to_remove = [\n                k for k, v in stations.items()\n                if current_time - v.get('last_update', 0) > timeout\n            ]\n            for k in stations_to_remove:\n                assignment_network.on_station_leave(k)\n                del stations[k]\n                pending_stations.pop(k, None)\n                socketio.emit('station_remove', {'station_id': k})\n                logger.info(f\"Removed inactive station: {k}\")\n\n            pis_to_remove = [\n                k for k, v in pis.items()\n                if current_time - v.get('last_update', 0) > timeout\n            ]\n            for k in pis_to_remove:\n                assignment_network.on_edge_leave(k)\n                del pis[k]\n                logger.info(f\"Removed inactive PI (edge): {k}\")\n        last_cleanup = current_time\n\n@app.before_request\ndef before_request():\n    cleanup_stations()\n\n@app.route('/')\ndef index():\n    return 'Dynamic Assignment Network'\n\n@app.route('/api/stations')\ndef get_stations():\n    with stations_lock:\n        return {\n            'stations': stations,\n            'timestamp': time.time()\n        }\n    \n@app.route('/api/config')\ndef get_config():\n    return jsonify({'web': config.get('web', {})})\n\n@socketio.on('connect')\ndef handle_connect():\n    logger.info('Client connected')\n    with stations_lock:\n        socketio.emit('initial_data', {\n            'stations': stations\n        }, to=request.sid)\n    logger.debug(f\"Sent initial_data to client {request.sid}\")\n\n@socketio.on('disconnect')\ndef handle_disconnect():\n    logger.info('Client disconnected')\n\n\n    "
  config.py: "import os\nimport yaml\nimport logging\n\nlogger = logging.getLogger(__name__)\n\ndef load_config():\n    config_file = os.getenv(\"CONFIG_FILE_PATH\", \"config.yml\")\n    if not os.path.isfile(config_file):\n        logger.error(f\"Config file '{config_file}' not found.\")\n        raise RuntimeError(f\"Config file '{config_file}' not found.\")\n    \n    try:\n        with open(config_file, \"r\") as f:\n            config = yaml.safe_load(f)\n        logger.debug(f\"Config loaded: {config}\")\n        if not config or 'mqtt' not in config or 'web' not in config:\n            logger.error(\"Invalid configuration or missing required sections (mqtt, web)\")\n            raise RuntimeError(\"Invalid configuration\")\n        return config\n    except Exception as e:\n        logger.error(f\"Error reading config: {e}\")\n        raise RuntimeError(f\"Error reading config: {e}\")"
  config.yml: |-
    mqtt:
      broker_ip: "iotwx.ucar.edu"
      broker_port: 1883
      msg_topic: sensors/#
      assignment_timeout: 60
    web:
      host:  10.2.2.153
      port: 5000
    map_web:
      host:  10.2.2.153
      port: 5001
    assignment:
      hysteresis: 0.1
      rssi_min: -120
      rssi_max: -30
      rebalance_interval: 600  # Reduced load
  docker-compose.yml: "version: '3.8'\nservices:\n  dynamic_assignment_network:\n    build:\n      context: .\n      dockerfile: Dockerfile\n    ports:\n      - \"5000:5000\"\n    environment:\n      - APP_MODULE=app:app  # Defined here for dynamic_assignment_network\n      - APP_PORT=5000\n      - GUNICORN_WORKERS=2\n      - GUNICORN_TIMEOUT=12000\n      - GUNICORN_WORKER_CLASS=geventwebsocket.gunicorn.workers.GeventWebSocketWorker\n    volumes:\n      - .:/app\n    networks:\n      - app-network\n\n  map_server:\n    build:\n      context: .\n      dockerfile: Dockerfile\n    ports:\n      - \"5001:5001\"\n    environment:\n      - APP_MODULE=map_app:app  # Defined here for map_server\n      - APP_PORT=5001 \n      - GUNICORN_WORKERS=5\n      - GUNICORN_TIMEOUT=30\n      - GUNICORN_WORKER_CLASS=geventwebsocket.gunicorn.workers.GeventWebSocketWorker\n    volumes:\n      - .:/app\n    depends_on:\n      - dynamic_assignment_network\n    networks:\n      - app-network\n\nnetworks:\n  app-network:\n    driver: bridge"
  dockerfile: |-
    # Use Python 3.11 slim base image
    FROM python:3.11-slim

    # Set working directory
    WORKDIR /app

    # Install system dependencies
    RUN apt-get update && apt-get install -y \
        gcc \
        libffi-dev \
        && rm -rf /var/lib/apt/lists/*

    # Copy requirements.txt and install dependencies
    COPY requirements.txt .
    RUN pip install --no-cache-dir -r requirements.txt

    # Copy application code and config
    COPY app.py .
    COPY map_app.py .
    COPY mqtt_client.py .
    COPY network.py .
    COPY config.py .
    COPY config.yml .

    # Create templates/ directory and copy templates
    RUN mkdir -p /app/templates
    COPY templates/ /app/templates/

    # Expose dynamic port
    ARG APP_PORT=5000
    EXPOSE ${APP_PORT}

    # Run Gunicorn with gevent, using environment variables
    CMD gunicorn -w ${GUNICORN_WORKERS:-1} --timeout ${GUNICORN_TIMEOUT:-120} -b 0.0.0.0:$APP_PORT --worker-class ${GUNICORN_WORKER_CLASS:-geventwebsocket.gunicorn.workers.GeventWebSocketWorker} $APP_MODULE
  dynamic_assignment_network.py: "import os\nimport paho.mqtt.client as mqtt\nfrom flask import Flask, render_template\nfrom flask_socketio import SocketIO\nimport time\nimport yaml\nfrom collections import defaultdict\nfrom datetime import datetime, timezone\nimport json\nfrom threading import Lock\nimport logging\nfrom flask import request\n\n# Configure logging\nlogging.basicConfig(\n    level=logging.DEBUG,\n    format='%(asctime)s [%(levelname)s] %(message)s',\n    datefmt='%Y-%m-%d %H:%M:%S'\n)\nlogger = logging.getLogger(__name__)\n\n# Load configuration\ndef load_config():\n    config_file = os.getenv(\"CONFIG_FILE_PATH\", \"config.yml\")\n    if not os.path.isfile(config_file):\n        logger.error(f\"Config file '{config_file}' not found.\")\n        raise RuntimeError(f\"Config file '{config_file}' not found.\")\n    \n    try:\n        with open(config_file, \"r\") as f:\n            config = yaml.safe_load(f)\n        logger.debug(f\"Config loaded: {config}\")\n        return config\n    except Exception as e:\n        logger.error(f\"Error reading config: {e}\")\n        raise RuntimeError(f\"Error reading config: {e}\")\n\nconfig = load_config()\nif not config or 'mqtt' not in config or 'web' not in config:\n    logger.error(\"Invalid configuration or missing required sections (mqtt, web)\")\n    raise RuntimeError(\"Invalid configuration\")\n\n# Global variables\nstations = defaultdict(dict)\nstations_lock = Lock()\napp = Flask(__name__)\napp.config['SECRET_KEY'] = os.urandom(24)\nallowed_origins = [\n    \"*\",\n    \"http://localhost:5000\",\n] + os.getenv(\"ALLOWED_ORIGINS\", \"\").split(\",\")\nallowed_origins = [origin for origin in allowed_origins if origin]\nlogger.info(f\"Allowed CORS origins: {allowed_origins}\")\nsocketio = SocketIO(app, cors_allowed_origins=allowed_origins, async_mode='eventlet', logger=True, engineio_logger=True)\n\n# Initialize MQTT client\nclass MQTTClient:\n    def __init__(self):\n        self.client = mqtt.Client(protocol=mqtt.MQTTv311, clean_session=True)\n        self.client.on_connect = self.on_connect\n        self.client.on_message = self.on_message\n        self.client.on_disconnect = self.on_disconnect\n        self.connected = False\n        \n    def connect(self):\n        try:\n            logger.debug(f\"Connecting to MQTT broker {config['mqtt']['broker_ip']}:{config['mqtt']['broker_port']}\")\n            self.client.connect(\n                config['mqtt']['broker_ip'],\n                port=int(config['mqtt']['broker_port']),\n                keepalive=60\n            )\n            self.client.loop_start()\n            return True\n        except Exception as e:\n            logger.error(f\"MQTT connection failed: {e}\")\n            self.connected = False\n            return False\n    \n    def reconnect(self):\n        if not self.connected:\n            logger.warning(\"Attempting MQTT reconnection...\")\n            return self.connect()\n        return True\n    \n    def on_connect(self, client, userdata, flags, rc):\n        if rc == 0:\n            logger.info(f\"Connected to MQTT broker at {config['mqtt']['broker_ip']}:{config['mqtt']['broker_port']}\")\n            self.connected = True\n            client.subscribe(config['mqtt']['msg_topic'], qos=1)\n            logger.info(f\"Subscribed to topic: {config['mqtt']['msg_topic']}\")\n        else:\n            logger.error(f\"Connection failed with code {rc}\")\n            self.connected = False\n    \n    def on_disconnect(self, client, userdata, rc):\n        logger.warning(f\"Disconnected from MQTT broker with code {rc}\")\n        self.connected = False\n    \n    def on_message(self, client, userdata, msg):\n        try:\n            logger.debug(f\"Raw MQTT message received on topic {msg.topic}\")\n            try:\n                payload = msg.payload.decode('utf-8')\n            except UnicodeDecodeError as e:\n                logger.error(f\"Failed to decode MQTT payload: {e}\")\n                return\n            \n            try:\n                packet_data = json.loads(payload)\n            except json.JSONDecodeError as e:\n                logger.error(f\"Invalid JSON in MQTT payload: {e}\")\n                return\n                \n            logger.info(\n                f\"Received MQTT message on topic '{msg.topic}' at {datetime.now(timezone.utc).isoformat()}:\\n\"\n                f\"Payload: {json.dumps(packet_data, indent=2)}\"\n            )\n            \n            station_id = packet_data.get('station_id')\n            if not isinstance(station_id, str) or not station_id:\n                logger.warning(f\"Invalid or missing station_id in packet\")\n                return\n\n            edge_id = packet_data.get('edge_id')\n            timestamp = packet_data.get('timestamp')\n            if not timestamp:\n                logger.warning(f\"Missing timestamp in packet, using current time\")\n                timestamp = datetime.now(timezone.utc).isoformat()\n                \n            sensor = packet_data.get('sensor')\n            measurement = packet_data.get('measurement')\n            data = packet_data.get('data')\n            rssi = packet_data.get('rssi')\n\n            normalized_data = {}\n            sensor_prefix = sensor[:5] if sensor else 'unkno'\n            has_gps = False\n            if isinstance(data, (int, float, str)):\n                normalized_data[f\"{measurement}({sensor_prefix})\"] = data\n            elif isinstance(data, dict) and len(data) == 3:\n                try:\n                    normalized_data['latitude'] = data['latitude']\n                    normalized_data['longitude'] = data['longitude']\n                    has_gps = True\n                    logger.debug(f\"GPS data received for station {station_id}: {normalized_data['latitude']}, {normalized_data['longitude']}\")\n                    if 'gps_fix' in packet_data:\n                        normalized_data['gps_fix'] = bool(packet_data['gps_fix'])\n                except (ValueError, TypeError) as e:\n                    logger.warning(f\"Invalid latitude/longitude format in packet: {e}\")\n                    return\n            elif isinstance(data, dict):\n                for key, value in data.items():\n                    normalized_data[f\"{key}({sensor_prefix})\"] = value\n            else:\n                logger.warning(f\"Invalid data format in packet\")\n                return\n\n            station_update = {\n                'station_id': station_id,\n                'edge_id': edge_id,\n                'rssi': rssi,\n                'last_update': time.time(),\n                'timestamp': timestamp,\n\n            }\n            station_update.update(normalized_data)\n            \n            with stations_lock:\n                old_station = dict(stations[station_id])\n                stations[station_id].update(station_update)\n                logger.debug(f\"Updated station {station_id}: {stations[station_id]}\")\n                \n                # Only emit update if station has GPS data\n                if 'latitude' in stations[station_id] and 'longitude' in stations[station_id]:\n                    socketio.emit('station_update', {\n                        'station_id': station_id,\n                        'data': dict(stations[station_id])\n                    })\n                    logger.debug(f\"Emitted station_update for {station_id} with GPS\")\n                elif has_gps:\n                    # Emit if this message contains GPS, even if previously no GPS\n                    socketio.emit('station_update', {\n                        'station_id': station_id,\n                        'data': dict(stations[station_id])\n                    })\n                    logger.debug(f\"Emitted station_update for {station_id} due to new GPS\")\n                else:\n                    logger.debug(f\"Skipped emitting station_update for {station_id}: no GPS data\")\n            \n        except Exception as e:\n            logger.error(f\"Error processing message: {e}\")\n\nmqtt_client = MQTTClient()\n\n# Periodic cleanup and MQTT reconnection\nlast_cleanup = time.time()\ndef cleanup_stations():\n    global last_cleanup\n    current_time = time.time()\n    if current_time - last_cleanup >= 1:\n        mqtt_client.reconnect()\n        timeout = config['mqtt'].get('assignment_timeout', 60)\n        with stations_lock:\n            to_remove = [k for k, v in stations.items() \n                        if current_time - v.get('last_update', 0) > timeout]\n            for k in to_remove:\n                del stations[k]\n                socketio.emit('station_remove', {'station_id': k})\n                logger.info(f\"Removed stale station: {k}\")\n        last_cleanup = current_time\n\n@app.before_request\ndef before_request():\n    cleanup_stations()\n\n@app.route('/')\ndef index():\n    return render_template('map.html')\n\n@app.route('/api/stations')\ndef get_stations():\n    with stations_lock:\n        # Only return stations with GPS data\n        return {\n            'stations': stations,\n            'timestamp': time.time()\n        }\n\n@socketio.on('connect')\ndef handle_connect():\n    logger.info('Client connected')\n    with stations_lock:\n        socketio.emit('initial_data', {\n            'stations': stations\n        }, to=request.sid)\n    logger.debug(f\"Sent initial_data to client {request.sid}\")\n\n@socketio.on('disconnect')\ndef handle_disconnect():\n    logger.info('Client disconnected')\n\n# Start MQTT client\nlogger.info(\"Starting MQTT client\")\nmqtt_client.connect()"
  map_app.py: |+
    import yaml
    import time
    import logging
    from flask import Flask, render_template, jsonify,send_from_directory
    from flask_socketio import SocketIO
    import requests

    app = Flask(__name__)
    app.config['SECRET_KEY'] = 'map_secret'
    socketio = SocketIO(app, async_mode='gevent', cors_allowed_origins=["*","http://10.219.130.204:5001", "http://localhost:5001"])
    logging.basicConfig(level=logging.DEBUG, format='%(asctime)s [%(levelname)s] %(message)s')

    # Load config
    with open('config.yml', 'r') as f:
        config = yaml.safe_load(f)

    MAIN_SERVER_URL = f"http://{config['web']['host']}:{config['web']['port']}"



    @app.route('/')
    def index():
        return send_from_directory('templates', 'map.html')

    @app.route('/api/stations')
    def get_stations():
        try:
            start = time.time()  # Ensure time is imported
            response = requests.get(f'{MAIN_SERVER_URL}/api/stations')
            response.raise_for_status()
            delta_time = time.time() - start
            return jsonify(response.json())
        except Exception as e:
            app.logger.error(f"Error fetching stations: {e}")
            return jsonify({'stations': {}}), 500

    @app.route('/api/config')
    def get_config():
        return jsonify({'map_web': config.get('map_web', {})})

    @app.route('/favicon.ico')
    def favicon():
        return send_from_directory('static', 'favicon.ico')

    @socketio.on('connect')
    def handle_connect():
        try:
            response = requests.get(f'{MAIN_SERVER_URL}/api/stations')
            socketio.emit('initial_data', response.json())
            app.logger.info('Map client connected')
        except Exception as e:
            app.logger.error(f"Error sending initial data: {e}")

  mqtt_client.py: "import datetime\nimport time\nimport json\nimport logging\nimport paho.mqtt.client as mqtt\nfrom threading import Lock\nfrom datetime import datetime, timezone\nclass MQTTClient:\n    def __init__(self, config, stations, pis, stations_lock, pending_stations, assignment_network, socketio):\n        self.config = config\n        self.stations = stations\n        self.pis = pis\n        self.stations_lock = stations_lock\n        self.pending_stations = pending_stations\n        self.assignment_network = assignment_network\n        self.socketio = socketio\n        self.logger = logging.getLogger(__name__)\n        self.client = mqtt.Client()\n        self.client.on_connect = self.on_connect\n        self.client.on_message = self.on_message\n        self.connected = False\n\n\n    def connect(self,config):\n        try:\n            self.logger.debug(f\"Connecting to MQTT broker {config['mqtt']['broker_ip']}:{config['mqtt']['broker_port']}\")\n            self.client.connect(\n                config['mqtt']['broker_ip'],\n                port=int(config['mqtt']['broker_port']),\n                keepalive=60\n            )\n            self.client.loop_start()\n            return True\n        except Exception as e:\n            self.logger.error(f\"MQTT connection failed: {e}\")\n            self.connected = False\n            return False\n\n    def reconnect(self):\n        if not self.client.is_connected():\n            self.logger.info(\"Reconnecting to MQTT broker\")\n            self.client.reconnect()\n\n    def on_connect(self, client, userdata, flags, rc):\n        self.logger.info(f\"Connected to MQTT with code {rc}\")\n        client.subscribe(self.config['mqtt']['msg_topic'])\n        self.connected = True\n    \n    def publish_assignment(self, edge_id, station_id, status):\n        if not self.connected:\n            self.logger.warning(f\"Cannot publish assignment for {station_id} to {edge_id}: MQTT not connected\")\n            return\n        topic_template = self.config.get('mqtt', {}).get('edge_topic_template', 'edge/{edge_id}/assignments')\n        topic = topic_template.format(edge_id=edge_id)\n        message = json.dumps({\n            'station_id': station_id,\n            'status': status,\n            'timestamp': datetime.now(timezone.utc).isoformat()\n        })\n        try:\n            self.client.publish(topic, message, qos=1)\n            self.logger.info(f\"Published assignment to {topic}: {message}\")\n        except Exception as e:\n            self.logger.error(f\"Failed to publish assignment to {topic}: {e}\")\n\n\n    def on_message(self, client, userdata, msg):\n        try:\n            self.logger.debug(f\"Raw MQTT message received on topic {msg.topic}\")\n            payload = msg.payload.decode('utf-8')\n            packet_data = json.loads(payload)\n            self.logger.info(\n                f\"Received MQTT message on topic '{msg.topic}' at {datetime.now(timezone.utc).isoformat()}:\\n\"\n                f\"Payload: {json.dumps(packet_data, indent=2)}\"\n            )\n\n            station_id = packet_data.get('station_id')\n            if not isinstance(station_id, str) or not station_id:\n                self.logger.warning(f\"Invalid or missing station_id in packet\")\n                return\n\n            edge_id = packet_data.get('edge_id')\n            if not edge_id :\n                self.logger.warning(f\"Missing edge_id in packet for station {station_id}\")\n                return\n\n            rssi = packet_data.get('rssi')\n            timestamp = packet_data.get('timestamp') or datetime.now(timezone.utc).isoformat()\n            sensor = packet_data.get('sensor')\n            measurement = packet_data.get('measurement')\n            data = packet_data.get('data')\n\n            normalized_data = {}\n            sensor_prefix = sensor[:5] if sensor else 'unkno'\n            has_gps = False\n            if isinstance(data, (int, float, str)):\n                normalized_data[f\"{measurement}({sensor_prefix})\"] = data\n            elif isinstance(data, dict) and len(data) == 3 and 'latitude' in data and 'longitude' in data:\n                try:\n                    normalized_data['latitude'] = float(data['latitude'])\n                    normalized_data['longitude'] = float(data['longitude'])\n                    has_gps = True\n                    self.logger.debug(f\"GPS data received for station {station_id}: {normalized_data['latitude']}, {normalized_data['longitude']}\")\n                    if 'gps_fix' in packet_data:\n                        normalized_data['gps_fix'] = bool(packet_data['gps_fix'])\n                except (ValueError, TypeError) as e:\n                    self.logger.warning(f\"Invalid latitude/longitude format in packet: {e}\")\n                    return\n            elif isinstance(data, dict):\n                for key, value in data.items():\n                    normalized_data[f\"{key}({sensor_prefix})\"] = value\n            else:\n                self.logger.warning(f\"Invalid data format in packet\")\n                return\n\n            station_update = {\n                'station_id': station_id,\n                'edge_id': edge_id,\n                'rssi': rssi,\n                'last_update': time.time(),\n                'timestamp': timestamp,\n            }\n            station_update.update(normalized_data)\n\n            with self.stations_lock:\n                if edge_id:\n                    self.pis[edge_id] = {'last_update': time.time()}\n                    if edge_id not in self.assignment_network.edges:\n                        self.assignment_network.on_edge_join(edge_id)\n                        self.logger.info(f\"Added new edge server (PI): {edge_id}\")\n\n                is_new_station = station_id not in self.stations\n                if is_new_station:\n                    self.pending_stations[station_id] = time.time()\n                    self.stations[station_id] = {'seen_by': {}}\n                    self.logger.info(f\"Added new station: {station_id}\")\n\n                if edge_id and rssi is not None:\n                    self.stations[station_id]['seen_by'][edge_id] = rssi\n\n                self.stations[station_id].update(station_update)\n                self.logger.debug(f\"Updated station {station_id}: {self.stations[station_id]}\")\n\n                if station_id in self.pending_stations:\n                    creation_time = self.pending_stations[station_id]\n                    if time.time() - creation_time >= 5:\n                        if self.stations[station_id]['seen_by']:\n                            self.assignment_network.on_station_join(station_id, self.stations[station_id]['seen_by'])\n                            assignments = self.assignment_network.get_assignments()\n                            self.stations[station_id]['assigned_edge'] = assignments.get(station_id)\n                            self.logger.debug(f\"Assigned edge {self.stations[station_id]['assigned_edge']} to station {station_id} after delay\")\n                        del self.pending_stations[station_id]\n                else:\n                    if self.stations[station_id]['seen_by']:\n                        self.assignment_network.on_station_join(station_id, self.stations[station_id]['seen_by'])\n                        assignments = self.assignment_network.get_assignments()\n                        self.stations[station_id]['assigned_edge'] = assignments.get(station_id)\n                        self.logger.debug(f\"Updated assignment for station {station_id}: {self.stations[station_id]['assigned_edge']}\")\n\n                if 'latitude' in self.stations[station_id] and 'longitude' in self.stations[station_id]:\n                    self.socketio.emit('station_update', {\n                        'station_id': station_id,\n                        'data': dict(self.stations[station_id])\n                    })\n                    self.logger.debug(f\"Emitted station_update for {station_id} with GPS\")\n                elif has_gps:\n                    self.socketio.emit('station_update', {\n                        'station_id': station_id,\n                        'data': dict(self.stations[station_id])\n                    })\n                    self.logger.debug(f\"Emitted station_update for {station_id} due to new GPS\")\n\n        except Exception as e:\n            self.logger.error(f\"Error processing message: {e}\")\n        \n "
  network.py: |-
    import numpy as np
    import networkx as nx
    import logging
    import json

    logger = logging.getLogger(__name__)

    class Station:
        def __init__(self, station_id, seen_by):
            self.id = station_id
            self.seen_by = seen_by  # Dict[edge_id: rssi]
            logger.debug(f"Station {station_id} created with seen_by: {seen_by}")

    class EdgeServer:
        def __init__(self, edge_id):
            self.id = edge_id
            self.assigned_stations = set()
            logger.debug(f"EdgeServer {edge_id} created")

    class DynamicAssignmentNetwork:
        def __init__(self, mqtt_client, config, hysteresis=0.1, rssi_min=-120, rssi_max=-30):
            self.mqtt_client = mqtt_client
            self.config = config
            self.stations = {}  # station_id -> Station
            self.edges = {}     # edge_id -> EdgeServer
            self.station_to_edge = {}  # station_id -> edge_id
            self.hysteresis = hysteresis
            self.rssi_min = rssi_min
            self.rssi_max = rssi_max
            logger.info(f"DynamicAssignmentNetwork initialized with hysteresis={hysteresis}, rssi_min={rssi_min}, rssi_max={rssi_max}")

        def score(self, station, edge_id):
            if not self.stations:
                logger.warning("No stations available for scoring")
                return 0
            rssi_score = (station.seen_by[edge_id] - self.rssi_min) / (self.rssi_max - self.rssi_min)
            load_score = 1 - (len(self.edges[edge_id].assigned_stations) / len(self.stations))
            score = 0.7 * rssi_score + 0.3 * load_score
            current_edge = self.station_to_edge.get(station.id)
            if current_edge == edge_id:
                score += self.hysteresis
            logger.debug(f"Score for station {station.id} to edge {edge_id}: rssi_score={rssi_score:.2f}, load_score={load_score:.2f}, total={score:.2f}")
            return score

        def assign_station(self, station):
            reachable_edges = station.seen_by
            if not reachable_edges:
                self.station_to_edge[station.id] = None
                logger.warning(f"No reachable edges for station {station.id}")
                return None
            best_edge = max(reachable_edges, key=lambda e: self.score(station, e))
            self.station_to_edge[station.id] = best_edge
            self.edges.setdefault(best_edge, EdgeServer(best_edge)).assigned_stations.add(station.id)
            logger.info(f"Assigned station {station.id} to edge {best_edge}")
            # Publish assignment
            if self.mqtt_client:
                try:
                    self.mqtt_client.publish_assignment(best_edge, station.id, "assigned")
                    logger.debug(f"Published assignment: station {station.id} to edge {best_edge}")
                except Exception as e:
                    logger.error(f"Failed to publish assignment for station {station.id} to edge {best_edge}: {e}")
            return best_edge

        def rebalance_all(self):
            station_ids = list(self.stations.keys())
            edge_ids = list(self.edges.keys())
            logger.info(f"Rebalancing: {len(station_ids)} stations, {len(edge_ids)} edges")

            if not station_ids or not edge_ids:
                logger.warning("No stations or edges to rebalance")
                for sid in station_ids:
                    if self.station_to_edge.get(sid):
                        old_edge = self.station_to_edge[sid]
                        self.station_to_edge[sid] = None
                        if self.mqtt_client and old_edge in self.edges:
                            try:
                                self.mqtt_client.publish_assignment(old_edge, sid, "unassigned")
                                logger.debug(f"Published unassignment: station {sid} from edge {old_edge}")
                            except Exception as e:
                                logger.error(f"Failed to publish unassignment for station {sid} from edge {old_edge}: {e}")
                for es in self.edges.values():
                    es.assigned_stations.clear()
                return

            valid_stations = [sid for sid in station_ids if self.stations[sid].seen_by]
            if not valid_stations:
                logger.warning("No valid stations with seen_by data")
                self.station_to_edge.clear()
                return

            # Store old assignments for comparison
            old_assignments = dict(self.station_to_edge)
            logger.debug(f"Old assignments: {json.dumps(old_assignments, indent=2)}")

            G = nx.DiGraph()
            source = 'source'
            sink = 'sink'
            G.add_node(source, demand=-len(valid_stations))
            G.add_node(sink, demand=len(valid_stations))
            for sid in valid_stations:
                G.add_node(f'station_{sid}')
            for eid in edge_ids:
                G.add_node(f'edge_{eid}')

            for sid in valid_stations:
                G.add_edge(source, f'station_{sid}', capacity=1, weight=0)
                station = self.stations[sid]
                for eid in edge_ids:
                    if eid in station.seen_by:
                        score = self.score(station, eid)
                        G.add_edge(f'station_{sid}', f'edge_{eid}', capacity=1, weight=-score)

            for eid in edge_ids:
                G.add_edge(f'edge_{eid}', sink, capacity=len(valid_stations), weight=0)

            try:
                flow_dict = nx.min_cost_flow(G)
                logger.debug(f"Min-cost flow computed: {json.dumps(flow_dict, indent=2)}")
                for es in self.edges.values():
                    es.assigned_stations.clear()
                self.station_to_edge.clear()
                for sid in station_ids:
                    self.station_to_edge[sid] = None

                for sid in valid_stations:
                    station_node = f'station_{sid}'
                    for edge_node, flow in flow_dict[station_node].items():
                        if flow > 0 and edge_node.startswith('edge_'):
                            eid = edge_node[5:]
                            self.station_to_edge[sid] = eid
                            self.edges[eid].assigned_stations.add(sid)
                            logger.info(f"Assigned station {sid} to edge {eid}")

                # Publish assignment changes
                if self.mqtt_client:
                    for sid in valid_stations:
                        old_edge = old_assignments.get(sid)
                        new_edge = self.station_to_edge.get(sid)
                        if old_edge != new_edge:
                            if old_edge and old_edge in self.edges:
                                try:
                                    self.mqtt_client.publish_assignment(old_edge, sid, "unassigned")
                                    logger.debug(f"Published unassignment: station {sid} from edge {old_edge}")
                                except Exception as e:
                                    logger.error(f"Failed to publish unassignment for station {sid} from edge {old_edge}: {e}")
                            if new_edge:
                                try:
                                    self.mqtt_client.publish_assignment(new_edge, sid, "assigned")
                                    logger.debug(f"Published assignment: station {sid} to edge {new_edge}")
                                except Exception as e:
                                    logger.error(f"Failed to publish assignment for station {sid} to edge {new_edge}: {e}")

            except nx.NetworkXUnfeasible:
                logger.error("No feasible flow found; falling back to greedy assignment")
                for es in self.edges.values():
                    es.assigned_stations.clear()
                for sid in valid_stations:
                    self.assign_station(self.stations[sid])

        def on_station_join(self, station_id, seen_by):
            valid_seen_by = {eid: rssi for eid, rssi in seen_by.items() if eid in self.edges}
            if not valid_seen_by and seen_by:
                logger.warning(f"No valid edge IDs in seen_by for station {station_id}: {seen_by}")
            station = Station(station_id, valid_seen_by)
            self.stations[station_id] = station
            logger.info(f"Station {station_id} joined with seen_by: {valid_seen_by}")
            self.assign_station(station)
            # self.rebalance_all()

        def on_station_leave(self, station_id):
            current_edge = self.station_to_edge.get(station_id)
            if current_edge and current_edge in self.edges:
                self.edges[current_edge].assigned_stations.discard(station_id)
                logger.info(f"Station {station_id} unassigned from edge {current_edge}")
            self.stations.pop(station_id, None)
            self.station_to_edge.pop(station_id, None)
            logger.info(f"Station {station_id} left")
            # self.rebalance_all()

        def on_edge_join(self, edge_id):
            self.edges[edge_id] = EdgeServer(edge_id)
            logger.info(f"Edge {edge_id} joined")
            # self.rebalance_all()

        def on_edge_leave(self, edge_id):
            if edge_id not in self.edges:
                logger.warning(f"Edge {edge_id} not found for removal")
                return
            reassigned_stations = self.edges[edge_id].assigned_stations.copy()
            self.edges.pop(edge_id)
            logger.info(f"Edge {edge_id} left, reassigning {len(reassigned_stations)} stations")
            for station_id in reassigned_stations:
                self.station_to_edge[station_id] = None
                if station_id in self.stations:
                    self.stations[station_id].seen_by.pop(edge_id, None)
                if self.mqtt_client:
                    try:
                        self.mqtt_client.publish_assignment(edge_id, station_id, "unassigned")
                        logger.debug(f"Published unassignment: station {station_id} from edge {edge_id}")
                    except Exception as e:
                        logger.error(f"Failed to publish unassignment for station {station_id} from edge {edge_id}: {e}")
            # self.rebalance_all()

        def get_assignments(self):
            logger.debug(f"Current assignments: {json.dumps(self.station_to_edge, indent=2)}")
            return dict(self.station_to_edge)

        def get_edge_loads(self):
            loads = {eid: len(es.assigned_stations) for eid, es in self.edges.items()}
            logger.debug(f"Edge loads: {json.dumps(loads, indent=2)}")
            return loads
  requirements.txt: |
    flask==3.1.1
    werkzeug==3.1.3
    flask-socketio==5.4.1
    paho-mqtt==2.1.0
    pyyaml==6.0.2
    gunicorn==23.0.0
    networkx==3.5
    numpy==2.3.0
    gevent==25.5.1
    gevent-websocket==0.10.1
    requests==2.32.4
    python-socketio==5.13.0
    python-engineio==4.12.2
kind: ConfigMap
metadata:
  labels:
    io.kompose.service: dynamic-assignment-network
  name: dynamic-assignment-network-cm0
